Keywords : Malware , Antivirus , Machine Learning , Feature Extraction , Random Forest , SVM , Neural Networks , Classification . 
I . 
INTRODUCTION The AV-TEST institute registers every day over 250,000 new malware [ 1 ] . 
Since novel malicious codes change constantly their signatures , static methods are not suitable to detect them . 
In the last two decades , the introduction of machine learning techniques had a great added value in detecting new malware . 
This is thanks to their generalization ability . 
Using relevant features as input , the chosen machine learning model learns and subsequently becomes able to make a good decision while confronted to a new file . 
The choice of both the appropriate input features and the classification model leads to the improvement of the results . 
In this article , multiple kinds of input features used for malware detection will be reviewed . 
Different machine learning classification techniques deployed in this field will be examined and classified . 
The results will be analyzed . 
II . 
FEATURE EXTRACTION The choice of input features is a primary task in every machine learning research . 
In malware detection field , these features can be either some raw information contained in the files , or the result of processing this raw information . 
Both benign and malicious files are considered for the training of the chosen model . 
But , which features are worthy to adopt ? 
In this section , we will review the most extracted features in machine learning researches for malware detection . 
A. Signatures Extraction Traditional antivirus programs rely on the signature-based static technique . 
This technique considers iteratively a known malware file , extracts some code from its header , or calculates a numerical value of it , like an MD5 hash for instance . 
All the obtained attributes , called signatures , are stored in a database to check each scanned file against them . 
Even if this technique generates no false positive , which is to say no benign file can be wrongfully designed as malicious , it would never detect new threats , as they use novel signatures . 
Schultz et al . 
in their study in 2001 [ 2 ] , entitled “ Data mining methods for detection of new malicious executable ” , used machine learning for malware detection . 
As baseline , they used the signatures extraction technique . 
Each signature was considered as a concatenation of some existent stings in the header of each malware to be used for training . 
B. DLL Function Calls Extraction According to Schultz et al . 
[ 2 ] , it is impossible to predict perfectly the behavior of a program without running it . 
However it is possible to estimate what it can do eventually . 
So they had the intuition that the information directing the behavior of the binary file is worthy to be extracted , that is the information related to DLL calls . 
Thereby , they extracted the following features in one of their three models : • The list of DLLs used by each binary file , • The list of DLL functions called by each file and • The number of functions called from each DLL . 
Those features were introduced using three different approaches . 
In the first approach , the feature vector included 30 Boolean values indicating whether a file calls a DLL or not . 
This vector is illustrated in Fig . 
1 . 
-advapi32 ˄ avicap32 ˄ … ˄ winmm ˄ -wsock32 In Fig . 
1 First feature vector : conjunction of DLL names [ 2 ] the second approach ( Fig.2 ) , each feature was constructed as a conjunction of a DLL name and a function call from that DLL . 
The feature vector consisted of 2229 Boolean values . 
˄ ˄ dvapi32.AdjustTokenPrivileges ( ) advapi32.GetFileSecurityA ( ) ˄ … wsock32.recv ( ) ˄ wsock32.send ( ) Fig . 
2 Second feature vector : conjunction of DLLs and function calls [ 2 ] In the third approach ( Fig . 
3 ) , they counted the number of different functions called within each DLL . 
In this case , the vector of features included 30 integer values . 
advapi32 = 2 ˄ avicap32 = 10 ˄ … ˄ winmm = 8 ˄ wsock32 = 2 Fig . 
3 Third feature vector : conjunction of DLLs and the number of functions called from each DLL [ 2 ] Masud et al. , in their study in 2007 [ 4 ] , entitled “ A hybrid model to detect malicious executables ” , used the PEDisassem tool [ 5 ] to disassemble the binaries . 
The disassembled files were analyzed , and DLL function calls were extracted . 
They defined an n-gram of DLL function calls as a sequence of n consecutive DLL calls appearing in a disassembled file . 
The sequence in Fig.4 represents a part of a disassembled file by omitting all the instructions but the DLL calls . 
Fig . 
5 shows the two corresponding 2-gram DLL sequences . 
“ … ” ; “ call KERNEL32.LoadResource ” ; “ … ” ; “ call USER32.TranslateMessage ” ; “ call USER32.DispatchMessageA ” Fig . 
4 Part of a disassembled file ( only DLL calls taken into account ) [ 4 ] ( 1 ) “ KERNEL32.LoadResource , USER32.TranslateMessage ” ( 2 ) “ USER32.TranslateMessage , USER32.DispatchMessageA ” “ … ” ; Fig . 
5 ‘ 2-gram ’ DLL sequences [ 4 ] C. Binary Sequences Extraction In a first approach of this technique , one takes the hexadecimal code of each binary file contained in the training database . 
The hexadecimal code can be seen as lines of code . 
Each single line , which is a sequence of sixteen consecutive bytes , is therefore considered as a single feature . 
Schultz et al . 
[ 2 ] used the hexdump utility ( Miller , 2000 ) to convert each executable into hexadecimal code and extract the different binary sequences . 
Fig.6 shows an example of a hexadecimal code . 
1f0e 0eba b400 cd09 b821 4c01 21cd 6854 7369 7020 6f72 7267 6d61 7220 7165 6975 6572 2073 694d 7263 736f 666f 2074 6957 646e 776f 2e73 0a0d 0024 0000 0000 0000 454e 3c05 026c 0009 0000 0000 0302 0004 0400 2800 3924 0001 0000 0004 0004 0006 000c 0040 0060 021e 0238 0244 02f5 0000 0001 0004 0000 0802 0032 1304 0000 030a Fig . 
6 Hexadecimal code example [ 2 ] A second approach of this technique consists of converting binary sequences to n-grams . 
In their study entitled “ Learning to detect and classify malicious executable in the wild ” [ 3 ] , Kolter and Maloof used the hexdump utility ( Miller , 1999 ) to convert each executable to hexadecimal code . 
They produced n-grams choosing n=4 , by combining each sequence of four consecutive bytes in a single term . 
For instance , the sequence ( ff 00 ab 3e 12 b3 ) corresponds to the following three 4-gram sequences : ( ff00ab3e ) , ( 00ab3e12 ) and ( ab3e12b3 ) . 
Each ngram is considered as a Boolean attribute that can be either present ( True ) or absent ( False ) in the executable . 
Barker et al. , in their study in 2017 , entitled “ Malware detection by eating a whole EXE ” [ 12 ] , chose similarly to extract byte sequences from the files . 
Instead of considering raw byte values as features , they used an embedding layer to map each byte to a feature vector of fixed and learned length . 
They chose to avoid raw byte values , as some of them are intrinsically closer to each other , they might be seen to have a close interpretation , which is considered false a priori , since the meaning of the bytes depends on the context . 
D. Assembly Sequences Extraction to Similarly the binary n-grams extraction method , assembly n-grams can be extracted as well . 
After disassembling the binaries , Masud et al . 
[ 4 ] extracted all the n-grams from the assembly instructions . 
In order to illustrate this approach , we take the sequence of assembly instructions represented by Fig . 
7 . 
The result will be the two 2-gram assembly sequences shown in Fig . 
8 . 
“ push eax ” ; “ mov eax , dword [ 0f34 ] ” ; “ add ecx , eax ” Fig . 
7 Assembly instructions sequence [ 4 ] ( 1 ) “ push eax ” ; “ mov eax , dword [ 0f34 ] ” ( 2 ) “ mov eax , dword [ 0f34 ] ” ; “ add ecx , eax ” Fig . 
8 ‘ 2-gram ’ assembly sequences [ 4 ] Siddiqui et al. , in their study for Trojans detection in 2008 [ 6 ] , also disassembled the binary files . 
The disassembly was obtained using Data rescues ' IDA Pro [ 7 ] . 
However , they defined a sequence as a succession of assembly instructions until the arrival to a conditional or unconditional branch instruction , and/or a limit function is obtained . 
To illustrate this approach , Siddiqui et al . 
took the assembly code shown in Fig . 
9 . 
The sequences extracted from this piece of code are shown in Fig . 
10. eax , [ ebp-24h ] [ ebp-84h ] , eax mov dword ptr [ ebp-4 ] , 4 lea mov mov dword ptr [ ebp-8Ch ] , 4008h mov dword ptr [ ebp-94h ] , 8 mov dword ptr [ ebp-9Ch ] , 3 push 10h pop eax __vbaChkstk call lea esi , [ ebp-8Ch ] mov edi , esp movsd movsd movsd movsd push 10h eax pop __vbaChkstk call Fig . 
9 Portion of a disassembled Trojan [ 6 ] ( 1 ) mov lea mov mov mov mov push pop call ( 2 ) lea mov movsd movsd movsd movsd push pop call Fig . 
10 Assembly sequences extracted from the disassembled Trojan [ 6 ] E. PE File Header Fields Extraction The header of the PE file consists of several fields . 
These fields contain structural information of the executable file . 
This includes dynamic library references for binding , API import and export tables , different sections contained in the file , resource management data , thread local storage data ( TLS ) and different types of metadata . 
Multiple recent studies exploit this information for malware detection . 
In their structural data mining study for malware detection in 2009 [ 8 ] , Shafiq et al . 
were able to extract initially , 189 PE features , as represented on Table I . 
TABLE I : LIST OF FEATURES EXTRACTED FROM THE PE FILE [ 8 ] Type Quantity 73 7 9 22 30 9 9 9 21 189 binary Integer Integer Integer Integer Integer Integer Integer Integer Feature Description DLLs referred COFF file header Optional header – standard fields Optional header – Windows specific fields Optional header – data directories .text section – header fields .data section – header fields .rsrc section – header fields Resource directory table & resources Total In regard to Kumar et al. , they established a malware detection model to detect maliciousness of portable executable using integrated feature set in 2017 [ 14 ] . 
They used as input the values of PE header fields . 
The set of integrated features included 68 values , consisting of 28 raw features , 26 Boolean features ( expressing the existence or absence of certain values ) and 14 derived features . 
The derived features were constructed through the validation of raw values according to a set of rules . 
For instance , the raw value of the TimeDateStamp field is simply an integer indicating the number of seconds since 1969 . 
According to them , using this raw value would not be a powerful feature . 
Thereby , the value of this field was compared to valid dates ( from December 31 , 1969 at 4:00 pm until the date of the experiment ) . 
The resulting Boolean output was taken as feature . 
Table II summarizes all the derived features considered and their raw counterparts . 
TABLE II : RAW AND DERIVED FEATURES [ 14 ] Feature Entropy Compilation Time Section Name Packer Info FileSize FileInfo ImageBase SectionAlignment FileAlignment SizeOfImage Raw Value Binary value Integer String NA Integer String Integer Integer Integer Integer Derived Value Type Integer Boolean Integer Boolean Integer Integer Boolean Boolean Boolean Boolean Value [ -1,0-8 ] [ 0,1 ] [ 0,1 ] [ 0,1 ] [ 0,1 ] [ 0,1 ] [ 0,1 ] [ 0,1 ] Among other studies that also used PE header data , we cite the study of Karthik Raman in 2012 entitled `` Selecting features to classify malware '' [ 9 ] , and the study of Pablo et al . 
[ 11 ] , published in 2016 and entitled `` Towards an effective and efficient malware detection system '' . 
F. Machine Activity Metrics Extraction Burnap et al . 
in their study “ Malware classification using self-organizing feature maps and machine activity data ” in 2017 [ 16 ] , extracted some system-level activity metrics , by executing samples of malicious and benign executables in a Sandbox environment . 
These metrics are : 1 . 
2 . 
3 . 
4 . 
5 . 
6 . 
7 . 
8 . 
9 . 
CPU User Use ( percentage ) , CPU System Use ( percentage ) , RAM use ( count ) , SWAP use ( count ) , received packets ( count ) , received bytes ( count ) , sent packets ( count ) , sent bytes ( count ) and number of processes running ( count ) G. Entropy Signals Extraction The entropy measures the randomness in a given set of values [ 10 ] . 
The higher the entropy , the more random the data and thus the higher the content of information . 
For binary data , given that the values of a byte vary from 0 to 255 , the formula used for the entropy is : Where Pi is the probability of i in the code . 
Wojnowicz et al. , in their work in 2016 entitled `` Wavelet decomposition of software entropy reveals symptoms of malicious code '' [ 17 ] , relied merely on the entropy analysis . 
For each training file , several levels of resolution were chosen . 
For each level of resolution , the file was divided into chunks of code , and the entropy was calculated for each chunk of them , resulting in one discrete entropy signal per level of resolution . 
Subsequently , all the obtained signals were the features extracted in this first step . 
III . 
FEATURE SELECTION TECHNIQUES After the first feature extraction step , researchers mostly follow the second selection step . 
This step is essential for dimensionality reduction , getting rid of redundant data , reducing the learning and test times of the classifier , and thus improving the accuracy of new malware detection . 
The feature selection techniques , frequently used with machine learning for malware detection , will be described below . 
A . 
Information Gain The information gain is related to the entropy notion . 
It informs about the importance of a given attribute in the corresponding vector . 
We must therefore look for attributes with a high information gain . 
After the application of the information gain to the list of n-grams and DLL calls , Masud et al . 
[ 4 ] reserved 500 binary n-grams , 500 assembly n-grams and 500 DLL function calls . 
Masud et al . 
represented the equations of the entropy and the information gain as follows : Where : S : training data p ( s ) : total number of positive instances n ( s ) : total number of negative instances values ( A ) : set of all possible values for attribute A |S| = p ( s ) + n ( s ) Sv : subset of S where A= v |Sv| = pv + nv pv : total number of positive instances in Sv nv : total number of negative instances in Sv For the case of binary and assembly n-grams , an n-gram may be either present or absent . 
So each attribute A has only two possible values : v ɛ { 0 , 1 } . 
B. Redundant Feature Removal RFR The redundant feature removal technique eliminates both the features that do not vary at all and the ones that show a significant variation . 
These features have an approximately uniform-random behavior . 
Using this technique , all the entities whose values are either constant or have a variance greater than a given threshold , will be deleted [ 8 ] . 
In the PE-miner study [ 8 ] , Shafiq et al . 
employed this technique among others . 
Unfortunately , they did not specify the number of features obtained after its application . 
C. Principal Component Analysis PCA The principal component analysis is a procedure for reducing the number of variables and making the information less redundant . 
It uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of uncorrelated variables . 
It is at the same time a geometric approach ( the variables are represented in a new space , according to maximum inertia directions ) and a statistical approach ( the research focuses on independent axes that best explain the variability or variance of the data ) [ 13 ] . 
Siddiqui et al . 
[ 6 ] used this technique in their process of reducing the initial set of data . 
They started with 877 variables . 
After the application of PCA , they retained solely the variables that explained 95 % of the full variance of the dataset . 
As a result , they obtained 146 variables . 
D. Random Forest The random forest technique is a prominent technique for classification and regression . 
It is a notable feature selection technique as well . 
For feature selection , it calculates the importance of an attribute by removing it from the model , then calculating the decrease in either accuracy or Gini index . 
in For the selection of features , Siddiqui et al . 
[ 6 ] used both PCA and random forest two different approaches . 
Using random forest , they rejected the variables where the average decrease in accuracy was less than 10 % . 
Thereby , they retained only 84 variables from 877. techniques , Pablo et al . 
[ 11 ] took advantage of this technique as well . 
They combined it with another technique called Chi-Squared . 
They used the Chi-Squared method first , which allowed them to retain 68,800 features from a total number of 682,936 initial features that is 10 % of the entire set . 
Then they applied the random forest technique . 
They chose the ranking made by accuracy decrease . 
The reduction passed here by successive stages . 
They went from 68,800 features , to 10,000 features , then to 5000 , 1000 , 300 , 100 , 30 , 10 , and finally to 9 features . 
E. Calculation of Accuracy by Considering Each Attribute Separately Karthik Raman in his feature selection study [ 9 ] , considered the fields ’ values of the PE file header as features for the training of his classifier . 
He had the intuition that the different parts of the PE file header will be less correlated between them . 
Subsequently , the most important variables and the least correlated ones will be the variables generating the most important individual accuracy in each part of the header . 
The seven different parts of the header are : DataDirectory , OptionalHeader , Imports , Exports , Resources , Sections and FileHeader . 
Then , the seven fields generating the highest accuracy from each part were respectively : DebugSize , ExportSize , ResourceSize , VirtualSize2 and NumberOfSections . 
F. Self-Organizing Feature Map SOFM ImageVersion , IatRVA , Self-organizing feature maps SOFMs form a class of neural networks . 
They can be used for either classification or dimensionality reduction . 
Burnap et al . 
[ 16 ] used SOFMs to reduce the features dimensionality . 
Once a sample is received , it runs on a virtual environment for 5 minutes . 
The chosen nine machine activity metrics are taken every second , producing 300 vectors of nine values for each sample , in the 5-minute time window . 
Then , SOFMs are used to transform each 9-dimensional vector to a 2-dimensional vector . 
Therefore , 300 vectors of x-y coordinates , are used as features for the training of the model . 
G. Wavelet Transform the wavelet Various researches use transforms for dimensionality reduction . 
Wojnowicz et al . 
[ 17 ] used this method to the entropy signals at different levels of resolution . 
For each level of resolution , each training file was divided into chunks of code , then the average entropy of each chunk was calculated , resulting in a discrete entropy signal . 
This signal was then multiplied by appropriate wavelet functions to get some wavelet coefficients . 
After that , the spectral energy was calculated as the sum of the wavelet coefficients squares . 
The spectral energies gathered from each level of resolution were used as input features for the machine learning classifier . 
For the highest level of resolution , the files were divided into code chunks of 256 bytes each . 
For example , if a file size is 32 * 256 bytes , since 32 = 25 , the file will be decomposed 5 times ; to 21 , 22 , 23 , 24 , and 25 pieces , giving 5 levels of resolution . 
It will subsequently generate 5 features which are the spectral energies E1 , E2 , E3 , E4 and E5 . 
They used some other string features and entropy statistics for the training of their model . 
IV . 
MACHINE LEARNING CLASSIFIERS A . 
Support Vector Machine SVM A support vector machine is a well-known supervised learning model for both linear and non-linear problems . 
For linear classification , the technique is based on finding the optimal hyperplane that separates the data into two categories . 
This hyperplane is the one that maximizes the margin between two parallel hyperplanes which separate the two classes of data . 
Its non-linear classification is obtained by applying a kernel function to map the original input space to a high-dimensional feature space , altering to a linear problem . 
Masud et al . 
[ 4 ] used SVM as a single classification technique in their model . 
Siddiqui et al . 
[ 6 ] and Shafiq et al . 
[ 8 ] used SVM in addition to other classifiers , each at a time in order to make comparisons between the obtained results . 
As for Pablo et al . 
[ 11 ] , they chose to make comparisons between a combination of several models , to keep the combination of SVM and neural networks in their model . 
B . 
Random Forest A random forest is a technique based on a set of classification trees . 
Each tree is divided at each node taking into account random features . 
Each tree gets its classification . 
Therefore , the model selects the most chosen class among all trees . 
Siddiqui et al . 
[ 6 ] built their model with 100 classification trees . 
The number of variables tested at each division was ranged from 6 to 43 , depending on the number of selected variables in the dataset . 
They formed several combinations presenting several experiments , such as : • Random forest for classification using all the 877 extracted features ; • Random forest for classification using 146 features retained by PCA feature selection technique ; • Random forest for classification using 84 features retained by random forest feature selection technique . 
The best results were obtained using random forests for both feature selection and classification . 
Karthik Raman [ 9 ] opted for the use of random forest as the only technique for file classification . 
C. Neural Network A neural network or an artificial neural network ANN is an algorithm emulating the connections between neurons in the human brain . 
It is constructed from interconnected nodes . 
Those nodes are represented in an input layer , hidden layers for the processing of input information , and an output layer for the answer . 
An ANN is based on a number of parameters , which are updated following a learning rule , like Gradient Descent and Backpropagation . 
ANNs their effectiveness as a strong classification technique in many areas , especially while dealing with a huge amount of data . 
revealed Pablo et al . 
[ 11 ] used neural networks for classification in combination with support vector machines and random forests . 
After multiple tests of the three techniques , they opted for the following procedure . 
They started with a pretreatment of the nine best features they obtained . 
After that , they transformed all the original data by applying the SVM kernels to each feature , which means transforming the feature vector into another easily separable space . 
They subsequently used simultaneously three sets of data to constitute the input layer of the neural network classifier . 
These three sets are : • The initial set of data , built of nine features , • The set of features transformed by SVM kernels and • The results of the SVM classifier applied to the initial set of nine features . 
Their model gave an increase in both accuracy and speed of training . 
The training passed actually from few hours to few minutes . 
Barker et al . 
[ 12 ] chose neural networks as well . 
After the input layer , they introduced an embedding layer , followed by convolutional layers , recurrent neural networks and finally a fully connected layer . 
Convolutional neural networks are widely used in image processing because of their ability to learn the existence of a feature regardless of its position . 
Barker et al . 
found that the MS-DOS header is the only component of the PE file that has a fixed position . 
Each of PE header , code , resources , etc . 
can be placed anywhere . 
To better capture such a high-level localization invariance , they chose to use a convolutional neural network architecture . 
V. CLASSIFICATION OF THE STUDIED RESEARCHES There are several indicators to measure the performance of a given classifier . 
For the classification of the different studied researches in this paper , we are interested in the accuracy rate of each one of them . 
Accuracy is defined as the number of malicious files classified as malicious plus the number of benign files classified as benign , divided by the total number of the files . 
The results are shown in Table III . 
We should mention that for [ 16 ] , the precision rate was used instead of the accuracy . 
It is the number of malicious files classified as malicious , divided by the number of all the files classified as malicious . 
There are other metrics to measure the performance like the false positive rate , the true positive rate , the false negative rate , the true negative rate , etc . 
Several researches investigated in this paper use the k-fold cross-validation . 
This technique partitions the existing data set into iterative learning and test subsets , but does not use a new subset for the final test of the model . 
This can lead to an overfitting of the model to the training data , subsequently it would fail to generalize perfectly to previously unseen data . 
Therefore , an important factor is to check whether a classification model could generalize from previously seen data in the model training , to the new data exclusively used for the last test phase . 
TABLE III CLASSIFICATION OF THE OBTAINED RESULTS of x-y 300 vectors Feature Selection SOFMs . 
coordinates obtained None None Random forest : 84 features retained SOFMs . 
coordinates obtained Information gain : 1500 retained Chi-squared , features adopted Wavelet transform of the entropy signals features random forests . 
vectors 300 of x-y 9 Machine Learning Classifier Random forest Accuracy 86,70 % Random forest CNN + RNN + ANN Random forest Logistic regression SVM SVM and ANN Logistic regression 89,23 % 90,90 % 94,00 % 94,60 % 96,30 % 98,40 % 98,90 % Features 300 vectors of 9 machine activity metrics taken in a 5-minute time window . 
68 raw and derived values from the PE header fields Byte ( mapped ) sequences taken from the file bodies 877 assembly n-grams from the file bodies 300 vectors of 9 machine activity metrics taken in a 5-minute time window . 
Binary n-grams , assembly n-grams and DLL function calls 682936 features : PE info , DLLs and other static and dynamic information from VirusTotal site [ 15 ] [ 17 ] Most common strings observed in file corpus + entropy statistics + file entropy signals Ref [ 16 ] [ 14 ] [ 12 ] [ 6 ] [ 16 ] [ 4 ] [ 11 ] Burnap et al . 
[ 16 ] performed a first experiment using 10fold cross validation . 
In a second experiment , they used a new unseen set of data for the final test . 
By comparing the two experiments , we remark that the results of the random forest model decreased by more than 12 % from the first experiment to the second one , whereas those of the ANN model decreased by 2.45 % only . 
That demonstrates that a model based on an ANN provides stability between training and test datasets . 
Pablo et al . 
[ 11 ] also made such a comparison . 
In the first experiment they obtained an accuracy of 99.60 % , and after the application of their model to new malicious files , whose date of appearance was located after the date of the files used for training , the new accuracy was 98.40 % . 
The results of the ANN model decreased here by just 1.20 % . 
The references [ 11 ] , [ 12 ] , [ 16 ] and [ 17 ] are the only ones in this paper that used unseen data for the final tests , yet they are the ones that have frequently achieved the best results . 
In Table III , the results of [ 4 ] , [ 6 ] and [ 14 ] were taken into account for comparison reasons , knowing that it is very likely that they will decrease by using unseen data . 
VI . 
CONCLUSIONS The transformation of the input dataset into another easily exploitable space , brings a high gain in both data processing time and obtained results . 
This was achieved in the researches of this paper through the use of either the kernel functions defined by SVMs , or SOFMs , or the wavelet transform of the entropy signal which has shown its potential utility . 
The use of random forest for feature selection provides a significant benefit in reducing both the size of the dataset and the processing time . 
The logistic regression model , in its relative simplicity , has shown its efficacy in the researches that used it in this paper . 
Several reasons could be indicators for an exceeding success by using neural networks instead of logistic regression . 
Neural networks are based , in several cases , on the sigmoid function as activation function between the layers of the network . 
This function is the same used in logistic regression . 
Neural networks have a major aptitude of generalization . 
Deep neural networks are generally more powerful . 
The metrics taken from system-level activities could very well train the logistic regression classification model . 
However , it is difficult to introduce such features into anti-malware programs because of their high execution time . 
